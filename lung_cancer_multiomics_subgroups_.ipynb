{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bg9eFOhi7SXf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Data\n",
        "file_name = 'lung_omics_data_for_clusters.csv'\n",
        "multiomics_data = pd.read_csv(file_name, index_col=0)\n",
        "\n",
        "# Display the first few rows of the data\n",
        "print(multiomics_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "multiomics_data_scaled = scaler.fit_transform(multiomics_data)"
      ],
      "metadata": {
        "id": "5aNrZsrVCJDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Impute missing values with the mean\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "multiomics_data_imputed = pd.DataFrame(imputer.fit_transform(multiomics_data), columns=multiomics_data.columns)\n",
        "\n",
        "# Standardize the data\n",
        "multiomics_data_scaled = scaler.fit_transform(multiomics_data_imputed)"
      ],
      "metadata": {
        "id": "8IWMbIuqCQZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Autoencoder\n",
        "# Step 1: Load the Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Step 2: Load and Preprocess Your Data\n",
        "data = multiomics_data_imputed\n",
        "\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "\n",
        "# Step 3-5: Build the Autoencoder, Train it, and Extract Encoded Features\n",
        "input_dim = data_scaled.shape[1]\n",
        "encoding_dim = 2\n",
        "\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
        "decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
        "\n",
        "autoencoder = Model(input_layer, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
        "autoencoder.fit(data_scaled, data_scaled, epochs=100, batch_size=32, shuffle=True, validation_split=0.2)\n",
        "\n",
        "encoder = Model(input_layer, encoded)\n",
        "encoded_features = encoder.predict(data_scaled)\n",
        "\n",
        "# Step 6: Perform Clustering\n",
        "kmeans = KMeans(n_clusters=5, random_state=42)\n",
        "clusters = kmeans.fit_predict(encoded_features)\n",
        "\n",
        "# Visualize the results\n",
        "plt.scatter(encoded_features[:, 0], encoded_features[:, 1], c=clusters, cmap='viridis')\n",
        "plt.title('Autoencoder Clustering')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RXz7MOUoCRSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# The best clusters=5\n",
        "k = 5\n",
        "kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "# Perform clustering\n",
        "kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "cluster_labels = kmeans.fit_predict(multiomics_data_scaled)\n",
        "\n",
        "# Add cluster labels to the original data\n",
        "multiomics_data_imputed['Cluster'] = cluster_labels"
      ],
      "metadata": {
        "id": "iDst1aFoDaVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('mRNA.csv', index_col=0)\n",
        "\n",
        "# Convert expression values to numeric\n",
        "data.iloc[:, 1:] = data.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Group by 'Clusters' and find the top ten expressed genes in each cluster\n",
        "top_genes_by_cluster = data.groupby('Clusters').apply(lambda x: x.iloc[:, 1:].mean().nlargest(10).index.tolist())\n",
        "\n",
        "# Organize the results in a dictionary\n",
        "result_dict = {cluster: top_genes for cluster, top_genes in top_genes_by_cluster.iteritems()}\n",
        "\n",
        "# Display the result\n",
        "for cluster, top_genes in result_dict.items():\n",
        "    print(f\"Cluster {cluster}: {', '.join(top_genes)}\")"
      ],
      "metadata": {
        "id": "-rqaYAe2DiUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using gProfiler to convert gene ID to gene name"
      ],
      "metadata": {
        "id": "X-6WgjTZEECa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "protein_data = pd.read_csv('protein.csv', index_col=0)\n",
        "\n",
        "# Convert expression values to numeric\n",
        "protein_data.iloc[:, 1:] = protein_data.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Group by 'Clusters' and find the top ten expressed proteins in each cluster\n",
        "top_proteins_by_cluster = protein_data.groupby('Clusters').apply(lambda x: x.iloc[:, 1:].mean().nlargest(10).index.tolist())\n",
        "\n",
        "# Organize the results in a dictionary\n",
        "result_dict = {cluster: top_proteins for cluster, top_proteins in top_proteins_by_cluster.iteritems()}\n",
        "\n",
        "# Display the result\n",
        "for cluster, top_proteins in result_dict.items():\n",
        "    print(f\"Cluster {cluster}: {', '.join(top_proteins)}\")"
      ],
      "metadata": {
        "id": "eEyW7d-gD9Lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "labels_data = pd.read_csv('lung_omics_data_by_cluster.csv', index_col=0)\n",
        "\n",
        "# Define a dictionary to map clusters to labels\n",
        "cluster_label_mapping = {'C1': 'LUSC', 'C2': 'LUAD', 'C3': 'LUAD', 'C4':'LUSC','C5': 'LUSC'}\n",
        "\n",
        "# Add a new column 'label' based on the 'Clusters' column\n",
        "labels_data['label'] = labels_data['Clusters'].map(cluster_label_mapping)\n",
        "\n",
        "# Display the updated DataFrame\n",
        "print(labels_data.head())"
      ],
      "metadata": {
        "id": "zM8aff6lEVCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the data\n",
        "data = labels_data\n",
        "\n",
        "# Separate features and labels\n",
        "features = data.drop(['label', 'Clusters'], axis=1)\n",
        "labels = data['label']\n",
        "\n",
        "# Encode the 'Clusters' column\n",
        "label_encoder = LabelEncoder()\n",
        "data['Clusters'] = label_encoder.fit_transform(data['Clusters'])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Classifiers\n",
        "classifiers = {\n",
        "    'SVM': SVC(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'FFNN': MLPClassifier()\n",
        "}\n",
        "\n",
        "# Plot Heatmaps in a 3x2 grid\n",
        "fig, axes = plt.subplots(3, 2, figsize=(15, 15))\n",
        "\n",
        "for (label, classifier), ax_row in zip(classifiers.items(), axes):\n",
        "    for scenario, ax in zip(['Without Holdout', 'With Holdout'], ax_row):\n",
        "        if scenario == 'Without Holdout':\n",
        "            # Fit classifiers without holdout\n",
        "            classifier.fit(features, labels)\n",
        "            predictions = classifier.predict(features)\n",
        "            conf_matrix = confusion_matrix(labels, predictions)\n",
        "            accuracy = accuracy_score(labels, predictions)\n",
        "            cmap = 'Blues'\n",
        "        else:\n",
        "            # Fit classifiers with holdout\n",
        "            classifier.fit(X_train, y_train)\n",
        "            predictions = classifier.predict(X_test)\n",
        "            conf_matrix = confusion_matrix(y_test, predictions)\n",
        "            accuracy = accuracy_score(y_test, predictions)\n",
        "            cmap = 'Greens'\n",
        "\n",
        "        # Plot heatmap\n",
        "        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=cmap, xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_, ax=ax)\n",
        "        ax.set_title(f'{label} - {scenario}\\nAccuracy: {accuracy:.2%}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N8eiZVu2EerM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}